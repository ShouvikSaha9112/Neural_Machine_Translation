{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c62d060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Importing Deep learning Modules\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c336f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "\n",
    "df = pd.read_csv('thedataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5031e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Beng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10251</th>\n",
       "      <td>Tom told Mary that he was going to kill himsel...</td>\n",
       "      <td>টম মেরিকে বললো যে ও নিজেকে হত্যা করতে চলেছিলো,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10252</th>\n",
       "      <td>Tom's an irritating person to work with becaus...</td>\n",
       "      <td>টমের সঙ্গে কাজ করা খুব বিরক্তিকর কারণ ও কখনই ম...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10253</th>\n",
       "      <td>I thought doing this would be easy, but we've ...</td>\n",
       "      <td>আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সার...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10254</th>\n",
       "      <td>I thought that doing this would be easy, but w...</td>\n",
       "      <td>আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সার...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10255</th>\n",
       "      <td>January, February, March, April, May, June, Ju...</td>\n",
       "      <td>বছরের বারোটা মাস হলো জানুয়ারি, ফেব্রুয়ারি, ম...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Eng  \\\n",
       "10251  Tom told Mary that he was going to kill himsel...   \n",
       "10252  Tom's an irritating person to work with becaus...   \n",
       "10253  I thought doing this would be easy, but we've ...   \n",
       "10254  I thought that doing this would be easy, but w...   \n",
       "10255  January, February, March, April, May, June, Ju...   \n",
       "\n",
       "                                                    Beng  \n",
       "10251  টম মেরিকে বললো যে ও নিজেকে হত্যা করতে চলেছিলো,...  \n",
       "10252  টমের সঙ্গে কাজ করা খুব বিরক্তিকর কারণ ও কখনই ম...  \n",
       "10253  আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সার...  \n",
       "10254  আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সার...  \n",
       "10255  বছরের বারোটা মাস হলো জানুয়ারি, ফেব্রুয়ারি, ম...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c070fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to List\n",
    "\n",
    "english_sentences = df[\"Eng\"].tolist()\n",
    "bengali_sentences = df[\"Beng\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68930d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English words to sequence\n",
    "\n",
    "tokenizer_eng = Tokenizer()\n",
    "tokenizer_eng.fit_on_texts(english_sentences)\n",
    "eng_seq = tokenizer_eng.texts_to_sequences(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b294d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bengali words to sequence\n",
    "\n",
    "tokenizer_beng = Tokenizer()\n",
    "tokenizer_beng.fit_on_texts(bengali_sentences)\n",
    "beng_seq = tokenizer_beng.texts_to_sequences(bengali_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab595459",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
    "vocab_size_beng = len(tokenizer_beng.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906faf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding\n",
    "max_length = max(len(seq) for seq in eng_seq + beng_seq)\n",
    "eng_seq_padded = pad_sequences(eng_seq, maxlen=max_length, padding='post')\n",
    "beng_seq_padded = pad_sequences(beng_seq, maxlen=max_length, padding='post')\n",
    "eng_seq_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f39430",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "029a5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "\n",
    "encoder_inputs = Input(shape=(max_length,))\n",
    "enc_emb = Embedding(input_dim=vocab_size_eng, output_dim=embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad34c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "\n",
    "decoder_inputs = Input(shape=(max_length,))\n",
    "dec_emb_layer = Embedding(input_dim=vocab_size_beng, output_dim=embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size_beng, activation='softmax')\n",
    "output = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5700950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "440aee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation of model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cda6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(eng_seq_padded, beng_seq_padded, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cbb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train, X_train], y_train, validation_data=([X_val, X_val], y_val), epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f68d7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence):\n",
    "    seq = tokenizer_eng.texts_to_sequences([sentence])\n",
    "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
    "    translated = np.argmax(model.predict([padded, padded]), axis=-1)\n",
    "    print(seq)\n",
    "    \n",
    "    translated_sentence = []\n",
    "    for i in translated[0]:\n",
    "        if i in tokenizer_beng.index_word:\n",
    "            translated_sentence.append(tokenizer_beng.index_word[i])\n",
    "        else:\n",
    "            translated_sentence.append(' ')  \n",
    "        \n",
    "    return ' '.join(translated_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bfaaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = input('Enter your sentence:')\n",
    "translated_sentence = translate_sentence(input_sentence)\n",
    "print(f\"Translated: {translated_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
